import React, { useEffect, useRef, useState, useCallback } from "react";
import {
  Box,
  Typography,
  Paper,
  Button,
  Stack,
  MenuItem,
  Select,
  FormControl,
  InputLabel,
  CircularProgress,
} from "@mui/material";
import { SelfieSegmentation } from "@mediapipe/selfie_segmentation";
import { FaceMesh } from "@mediapipe/face_mesh";
import { Camera } from "@mediapipe/camera_utils";
import gifshot from "gifshot";
import SnapshotPreview from "./SnapshotPreview";
import { getExactAddress } from "./Helper";
import CheckCircleIcon from "@mui/icons-material/CheckCircle";
import RadioButtonUncheckedIcon from "@mui/icons-material/RadioButtonUnchecked";
import VerifiedIcon from "@mui/icons-material/Verified";
import { challenges } from "../utils/constants/SmartCamera";
import { useSomething } from "../utils/hooks/useSomething";
import { computeClarity, computeContrastScore, computeLightingScore, computeSharpnessScore } from "../utils/imageQualityHelpers";

const SmartCameraControl = ({ blurEnabled = true }) => {
  const videoRef = useRef(null);
  const outputCanvasRef = useRef(null);
  const bgCanvasRef = useRef(null);
  const personCanvasRef = useRef(null);
  const segmentationRef = useRef(null);
  const faceMeshRef = useRef(null);
  const cameraRef = useRef(null);
  const challengeImageCaptureRef = useRef(null);





  const [blurAmount, setBlurAmount] = useState(12);
  const [brightness, setBrightness] = useState(1);
  const [zoom, setZoom] = useState(1);
  const [isReady, setIsReady] = useState(false);
  const [aspectRatio, setAspectRatio] = useState(16 / 9);

  // Snapshot + Preview states
  const [previewOpen, setPreviewOpen] = useState(false);
  const [previewImage, setPreviewImage] = useState(null);
  const [snapshots, setSnapshots] = useState([]);
  const [location, setLocation] = useState(null);
  const [error, setError] = useState(null);
  const [qualityScore, setQualityScore] = useState({
    lighting: 0,
    sharpness: 0,
    clarity: 0,
  });

  // GIF creation
  const [gifSrc, setGifSrc] = useState(null);
  const [isCreatingGif, setIsCreatingGif] = useState(false);

  // Refs for dynamic values
  const blurRef = useRef(blurAmount);
  const brightnessRef = useRef(brightness);
  const zoomRef = useRef(zoom);
  const aspectRef = useRef(aspectRatio);
  
  // Function to capture and save image when challenge is completed
  const handleChallengeImageCapture = useCallback(() => {
    const canvas = outputCanvasRef.current;
    if (!canvas) return;

    // Capture image from canvas
    const imageData = canvas.toDataURL("image/png");
    
    // Add to snapshots for display and storage
    setSnapshots((prev) => [...prev, imageData]);
  }, []);
  
  // Update the ref whenever the callback changes
  useEffect(() => {
    challengeImageCaptureRef.current = handleChallengeImageCapture;
  }, [handleChallengeImageCapture]);
  
  const onChallengeCompleteCallback = useCallback((challengeIndex, challengeName) => {
    if (challengeImageCaptureRef.current) {
      challengeImageCaptureRef.current(challengeIndex, challengeName);
    }
  }, []);
  
  // useSomething hook
  const {
    isVerifying,
    completedChallenges,
    detectLivenessActions,
    handleStartVerification,
    handleStopVerification,
    isAllVerified,
  } = useSomething(onChallengeCompleteCallback);

  useEffect(() => {
    blurRef.current = blurAmount;
  }, [blurAmount]);
  useEffect(() => {
    brightnessRef.current = brightness;
  }, [brightness]);
  useEffect(() => {
    zoomRef.current = zoom;
  }, [zoom]);
  useEffect(() => {
    aspectRef.current = aspectRatio;
  }, [aspectRatio]);

  useEffect(() => {
    navigator.geolocation.getCurrentPosition(async (pos) => {
      const lat = pos.coords.latitude;
      const lon = pos.coords.longitude;

      const address = await getExactAddress(lat, lon);
      setLocation(address);
    });
  }, []);

 

  const startCamera = useCallback(async (video, mounted) => {
    try {
      if (!video) return;
      cameraRef.current = new Camera(video, {
        onFrame: async () => {
          await segmentationRef.current?.send({ image: video });
          if (isVerifying && faceMeshRef.current) {
            await faceMeshRef.current.send({ image: video });
          }
        },
        width: 1280,
        height: 720,
      });
      await cameraRef.current.start();
      if (mounted) setIsReady(true);
    } catch (err) {
      console.log("Camera start error:", err);
      setError("Camera access is blocked by your browser. Go to Settings ‚Üí Site Permissions to enable it.");
      setIsReady(false);
    }
  }, [isVerifying]);

  useEffect(() => {
    let mounted = true;
    const video = videoRef.current;

    if (!bgCanvasRef.current)
      bgCanvasRef.current = document.createElement("canvas");
    if (!personCanvasRef.current)
      personCanvasRef.current = document.createElement("canvas");

    const bgCanvas = bgCanvasRef.current;
    const personCanvas = personCanvasRef.current;

    const selfieSegmentation = new SelfieSegmentation({
      locateFile: (file) =>
        `https://cdn.jsdelivr.net/npm/@mediapipe/selfie_segmentation/${file}`,
    });
    selfieSegmentation.setOptions({ modelSelection: 1 });

    selfieSegmentation.onResults((results) => {
      if (!mounted || !video || !outputCanvasRef.current) return;

      const w = video.videoWidth;
      const h = video.videoHeight;
      if (!w || !h) return;

      const targetAspect = aspectRef.current;
      let outputW = w;
      let outputH = w / targetAspect;
      if (outputH > h) {
        outputH = h;
        outputW = h * targetAspect;
      }

      const offsetX = (w - outputW) / 2;
      const offsetY = (h - outputH) / 2;

      const outputCanvas = outputCanvasRef.current;
      outputCanvas.width = outputW;
      outputCanvas.height = outputH;

      bgCanvas.width = outputW;
      bgCanvas.height = outputH;
      personCanvas.width = outputW;
      personCanvas.height = outputH;

      const outCtx = outputCanvas.getContext("2d");
      const bgCtx = bgCanvas.getContext("2d");
      const personCtx = personCanvas.getContext("2d");

      const bAmount = blurRef.current;
      const bright = brightnessRef.current;
      const z = zoomRef.current;

      // Crop region to maintain aspect ratio
      const srcX = offsetX;
      const srcY = offsetY;
      const srcW = outputW;
      const srcH = outputH;

      // Background
      bgCtx.save();
      bgCtx.filter = `${
        blurEnabled && bAmount > 0 ? `blur(${bAmount}px)` : ""
      } brightness(${bright})`;
      bgCtx.drawImage(
        results.image,
        srcX,
        srcY,
        srcW,
        srcH,
        0,
        0,
        outputW,
        outputH
      );
      bgCtx.restore();

      // Person
      personCtx.save();
      personCtx.filter = `brightness(${bright})`;
      personCtx.drawImage(
        results.image,
        srcX,
        srcY,
        srcW,
        srcH,
        0,
        0,
        outputW,
        outputH
      );
      personCtx.globalCompositeOperation = "destination-in";
      personCtx.drawImage(
        results.segmentationMask,
        srcX,
        srcY,
        srcW,
        srcH,
        0,
        0,
        outputW,
        outputH
      );
      personCtx.restore();

      // Compose
      outCtx.save();
      outCtx.clearRect(0, 0, outputW, outputH);

      // Flip horizontally to show true camera view
      outCtx.translate(outputW, 0);
      outCtx.scale(-1, 1);

      // Apply zoom
      outCtx.translate(outputW / 2, outputH / 2);
      outCtx.scale(z, z);
      outCtx.translate(-outputW / 2, -outputH / 2);

      outCtx.drawImage(bgCanvas, 0, 0, outputW, outputH);
      outCtx.drawImage(personCanvas, 0, 0, outputW, outputH);

      // === Quality Scoring ===
      if (blurEnabled && outputCanvasRef.current) {
        try {
          const frame = personCtx.getImageData(0, 0, outputW, outputH);
          // compute robust metrics (fast thanks to downsampling)
          const lighting = computeLightingScore(frame);    // 0..100
          const sharpness = computeSharpnessScore(frame);  // 0..100 (higher = sharper)
          const contrast = computeContrastScore(frame);    // 0..100
          const clarity = computeClarity(lighting, sharpness, contrast);

          setQualityScore({
            lighting,
            sharpness, 
            clarity,
          });
        } catch (e) {
          console.log("Quality scoring error:", e);
        }
      }

      outCtx.restore();
    });

    segmentationRef.current = selfieSegmentation;

    // Initialize Face Mesh for liveness detection
    const faceMesh = new FaceMesh({
      locateFile: (file) =>
        `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`,
    });
    faceMesh.setOptions({
      maxNumFaces: 1,
      refineLandmarks: true,
      minDetectionConfidence: 0.5,
      minTrackingConfidence: 0.5,
    });

    faceMesh?.onResults((results) => {
      if (!mounted || !isVerifying) return;
      
      if (results?.multiFaceLandmarks && results?.multiFaceLandmarks?.length > 0) {
        const landmarks = results?.multiFaceLandmarks[0];
        detectLivenessActions(landmarks);
      }
    });

    faceMeshRef.current = faceMesh;

    startCamera(video, mounted);

    return () => {
      mounted = false;
      cameraRef.current?.stop();
      cameraRef.current = null;
      segmentationRef.current = null;
      faceMeshRef.current = null;
    };
  }, [blurEnabled, isVerifying, detectLivenessActions, startCamera]);

  const handleSnapshot = () => {
    const canvas = outputCanvasRef.current;
    if (!canvas) return;
    const imageData = canvas.toDataURL("image/png");
    setPreviewImage(imageData);
    setPreviewOpen(true);
  };

  const handleKeepSnapshot = () => {
    setSnapshots((prev) => [...prev, previewImage]);
    setPreviewOpen(false);
    setPreviewImage(null);
  };

  const handleRetakeSnapshot = () => {
    setPreviewOpen(false);
    setPreviewImage(null);
  };

  // ===== GIF CREATION =====
  const createGifFromSnapshots = () => {
    if (snapshots.length < 2) {
      alert("Please capture at least 2 snapshots to create a GIF.");
      return;
    }

    setIsCreatingGif(true);
    gifshot.createGIF(
      {
        images: snapshots,
        gifWidth: 480,
        gifHeight: 480 / aspectRatio,
        interval: 0.5, // frame delay in seconds
        numFrames: snapshots.length,
        frameDuration: 1,
        sampleInterval: 10,
        progressCallback: () => {},
      },
      (obj) => {
        setIsCreatingGif(false);
        if (!obj.error) {
          setGifSrc(obj.image);
        } else {
          console.log("GIF creation failed:", obj.error);
        }
      }
    );
  };

  // ===== UI CONTROLS =====
  const increaseBlur = () => setBlurAmount((v) => Math.min(50, v + 1));
  const decreaseBlur = () => setBlurAmount((v) => Math.max(0, v - 1));
  const increaseBrightness = () =>
    setBrightness((v) => Math.min(3, +(v + 0.1).toFixed(1)));
  const decreaseBrightness = () =>
    setBrightness((v) => Math.max(0.1, +(v - 0.1).toFixed(1)));
  const increaseZoom = () => setZoom((v) => Math.min(3, +(v + 0.1).toFixed(2)));
  const decreaseZoom = () => setZoom((v) => Math.max(1, +(v - 0.1).toFixed(2)));

  return (
    <Paper
      elevation={6}
      sx={{ p: 3, maxWidth: 500, m: "32px auto", borderRadius: 2 }}
    >
      <Typography variant="h6" fontWeight={700} mb={2}>
        Smart Camera
      </Typography>
      {error ? (
         <Box mb={2} p={2} bgcolor="#fdecea" borderRadius={1}>
          <Typography color="#b71c1c">{error}</Typography>
        </Box>
      ):(
        <>
      <Box sx={{ position: "relative", borderRadius: 2, overflow: "hidden" }}>
        <video
          ref={videoRef}
          autoPlay
          playsInline
          muted
          style={{ display: "none" }}
        />
        <canvas
          ref={outputCanvasRef}
          style={{
            width: "100%",
            height: "auto",
            aspectRatio: `${aspectRatio}`,
            display: "block",
            background: "#000",
          }}
        />
      </Box>

      <Stack direction="row" flexWrap="wrap" gap={2} mt={2} alignItems="center">
        <Typography>Blur</Typography>
        <Button onClick={decreaseBlur} disabled={!isReady}>
          -
        </Button>
        <Typography>{blurAmount}px</Typography>
        <Button onClick={increaseBlur} disabled={!isReady}>
          +
        </Button>

        <Typography>Brightness</Typography>
        <Button onClick={decreaseBrightness} disabled={!isReady}>
          -
        </Button>
        <Typography>{brightness.toFixed(1)}</Typography>
        <Button onClick={increaseBrightness} disabled={!isReady}>
          +
        </Button>

        <Typography>Zoom</Typography>
        <Button onClick={decreaseZoom} disabled={!isReady}>
          -
        </Button>
        <Typography>{zoom.toFixed(2)}x</Typography>
        <Button onClick={increaseZoom} disabled={!isReady}>
          +
        </Button>

        <FormControl size="small" sx={{ minWidth: 120 }}>
          <InputLabel>Aspect</InputLabel>
          <Select
            label="Aspect"
            value={aspectRatio}
            onChange={(e) => setAspectRatio(Number(e.target.value))}
            disabled={!isReady}
          >
            <MenuItem value={16 / 9}>16:9</MenuItem>
            <MenuItem value={4 / 3}>4:3</MenuItem>
            <MenuItem value={1}>1:1</MenuItem>
          </Select>
        </FormControl>

        <Button
          variant="contained"
          onClick={handleSnapshot}
          disabled={!isReady || isVerifying}
        >
          Capture
        </Button>

        <Button
          variant="contained"
          color={isAllVerified ? "success" : isVerifying ? "error" : "success"}
          onClick={isVerifying ? handleStopVerification : handleStartVerification}
          disabled={!isReady}
        >
          {isAllVerified ? "Verified" : isVerifying ? "Stop Verify" : "Verify"}
        </Button>
      </Stack>

      <Typography
        variant="caption"
        display="block"
        mt={1}
        color="text.secondary"
      >
        {isReady
          ? "Camera active"
          : "Starting camera... allow permission if prompted."}
      </Typography>

      {/* Liveness Detection Challenges */}
      {isVerifying && (
        <Box mt={3} p={2} bgcolor="#f5f5f5" borderRadius={2}>
          {isAllVerified ? (
            <Box
              sx={{
                display: "flex",
                flexDirection: "column",
                alignItems: "center",
                justifyContent: "center",
                py: 3,
                gap: 2,
              }}
            >
              <VerifiedIcon
                sx={{
                  fontSize: 64,
                  color: "#4caf50",
                }}
              />
              <Typography
                variant="h5"
                fontWeight={700}
                sx={{
                  color: "#2e7d32",
                  textAlign: "center",
                }}
              >
                Verified!
              </Typography>
              <Typography
                variant="body2"
                sx={{
                  color: "#424242",
                  textAlign: "center",
                }}
              >
                All challenges completed successfully
              </Typography>
            </Box>
          ) : (
            <>
              <Typography variant="subtitle1" fontWeight={600} mb={2}>
                Complete these challenges:
              </Typography>
              <Stack spacing={1.5}>
                {challenges.map((challenge, index) => (
                  <Box
                    key={index}
                    sx={{
                      display: "flex",
                      alignItems: "center",
                      gap: 1.5,
                      p: 1,
                      borderRadius: 1,
                      bgcolor: completedChallenges.has(index)
                        ? "#e8f5e9"
                        : "transparent",
                      transition: "background-color 0.3s",
                    }}
                  >
                    {completedChallenges.has(index) ? (
                      <CheckCircleIcon sx={{ color: "#4caf50" }} />
                    ) : (
                      <RadioButtonUncheckedIcon sx={{ color: "#9e9e9e" }} />
                    )}
                    <Typography
                      variant="body2"
                      sx={{
                        color: completedChallenges.has(index)
                          ? "#2e7d32"
                          : "#424242",
                        fontWeight: completedChallenges.has(index) ? 600 : 400,
                      }}
                    >
                      {challenge}
                    </Typography>
                  </Box>
                ))}
              </Stack>
            </>
          )}
        </Box>
      )}
      </>
      )}
      {snapshots.length > 0 && (
        <Box mt={3}>
          <Typography variant="subtitle1">Saved Snapshots:</Typography>
          <Box sx={{ display: "flex", gap: 2, flexWrap: "wrap", mt: 1 }}>
            {snapshots.map((img, i) => (
              <img
                key={i}
                src={img}
                alt={`snapshot-${i}`}
                style={{
                  width: 120,
                  borderRadius: 8,
                  border: "1px solid #ccc",
                }}
              />
            ))}
          </Box>

          <Box mt={2}>
            <Button
              variant="contained"
              color="secondary"
              onClick={createGifFromSnapshots}
              disabled={isCreatingGif}
            >
              {isCreatingGif ? (
                <CircularProgress size={20} sx={{ mr: 1 }} />
              ) : (
                "Create GIF"
              )}
            </Button>
          </Box>
        </Box>
      )}

      {/* === Generated GIF Preview === */}
      {gifSrc && (
        <Box mt={3} textAlign="center">
          <Typography variant="subtitle1">Generated GIF:</Typography>
          <img
            src={gifSrc}
            alt="Generated GIF"
            style={{
              maxWidth: "100%",
              borderRadius: 8,
              border: "2px solid #444",
            }}
          />
          <Box mt={1}>
            <Button
              variant="outlined"
              onClick={() => {
                const a = document.createElement("a");
                a.href = gifSrc;
                a.download = "smart_camera.gif";
                a.click();
              }}
            >
              Download GIF
            </Button>
          </Box>
        </Box>
      )}

      {blurEnabled && (
      <Box
        sx={{
          position: "absolute",
          bottom: 8,
          right: 8,
          bgcolor: "rgba(0,0,0,0.6)",
          color: "#fff",
          p: 1,
          borderRadius: 1,
          fontSize: "0.75rem",
          textAlign: "right",
          lineHeight: 1.3,
        }}
      >
        <div>üí° Lighting: {qualityScore.lighting}%</div>
        <div>üå´Ô∏è Sharpness: {qualityScore.sharpness}%</div>
        <div>üîç Clarity: {qualityScore.clarity}%</div>
      </Box>
      )}


      {/* Snapshot Preview Dialog */}
      <SnapshotPreview
        open={previewOpen}
        imageSrc={previewImage}
        onKeep={handleKeepSnapshot}
        onRetake={handleRetakeSnapshot}
        location={location}
      />
    </Paper>
  );
};

export default SmartCameraControl;
